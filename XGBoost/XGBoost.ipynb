{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f064ce",
   "metadata": {},
   "source": [
    "# XGBoost Algorithm From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d60ea8",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14cbfadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pmlb import fetch_data\n",
    "import time\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd56dec9",
   "metadata": {},
   "source": [
    "## The XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd684a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, depth):\n",
    "        self.depth = depth\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.split_feature = None\n",
    "        self.split_value = None\n",
    "        self.leaf_value = None\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred_prob):\n",
    "    epsilon = 1e-15\n",
    "    y_pred_prob = np.clip(y_pred_prob, epsilon, 1 - epsilon)\n",
    "    return -np.sum(y_true * np.log(y_pred_prob)) / len(y_true)\n",
    "\n",
    "def find_best_split(X, gradients):\n",
    "    best_feature, best_value, best_reduction = None, None, -float('inf')\n",
    "\n",
    "    for feature in range(X.shape[1]):\n",
    "        unique_values = np.unique(X[:, feature])\n",
    "        for value in unique_values:\n",
    "            left_indices = X[:, feature] <= value\n",
    "            right_indices = ~left_indices\n",
    "\n",
    "            left_gradients = gradients[left_indices]\n",
    "            right_gradients = gradients[right_indices]\n",
    "\n",
    "            reduction = np.sum(left_gradients**2) + np.sum(right_gradients**2) - np.sum(gradients**2)\n",
    "            if reduction > best_reduction:\n",
    "                best_feature, best_value, best_reduction = feature, value, reduction\n",
    "\n",
    "    return best_feature, best_value\n",
    "\n",
    "def build_tree(X, gradients, max_depth, current_depth=0):\n",
    "    if current_depth == max_depth or np.sum(gradients**2) < 1e-3:\n",
    "        leaf = TreeNode(depth=current_depth)\n",
    "        leaf.leaf_value = np.mean(gradients, axis=0)\n",
    "        return leaf\n",
    "\n",
    "    best_feature, best_value = find_best_split(X, gradients)\n",
    "\n",
    "    if best_feature is None:\n",
    "        leaf = TreeNode(depth=current_depth)\n",
    "        leaf.leaf_value = np.mean(gradients, axis=0)\n",
    "        return leaf\n",
    "\n",
    "    node = TreeNode(depth=current_depth)\n",
    "    node.split_feature = best_feature\n",
    "    node.split_value = best_value\n",
    "\n",
    "    left_indices = X[:, best_feature] <= best_value\n",
    "    right_indices = ~left_indices\n",
    "\n",
    "    node.left = build_tree(X[left_indices], gradients[left_indices], max_depth, current_depth + 1)\n",
    "    node.right = build_tree(X[right_indices], gradients[right_indices], max_depth, current_depth + 1)\n",
    "\n",
    "    return node\n",
    "\n",
    "def predict_tree(node, X):\n",
    "    if node.leaf_value is not None:\n",
    "        return node.leaf_value\n",
    "\n",
    "    if X[node.split_feature] <= node.split_value:\n",
    "        return predict_tree(node.left, X)\n",
    "    else:\n",
    "        return predict_tree(node.right, X)\n",
    "\n",
    "class MyXGBoostClassifier:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = []\n",
    "        self.num_classes = None  \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "\n",
    "        class_labels = np.unique(y)\n",
    "        num_classes = len(class_labels)\n",
    "        one_hot_y = np.eye(num_classes)[y]\n",
    "\n",
    "        predictions = np.zeros_like(one_hot_y) + np.mean(one_hot_y, axis=0) #0.5 nai ghetla\n",
    "        self.num_classes = len(np.unique(y))\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            gradients = one_hot_y - softmax(predictions) #log of odds chya jaagi softmax\n",
    "            tree = build_tree(X, gradients, max_depth=self.max_depth)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "            tree_predictions = np.array([predict_tree(tree, x) for x in X])\n",
    "            predictions += self.learning_rate * tree_predictions\n",
    "            #print(np.exp(predictions)/(1+np.exp(predictions)))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X = np.array(X)\n",
    "\n",
    "        num_classes = self.num_classes\n",
    "\n",
    "        predictions = np.zeros((len(X), len(self.trees), num_classes))\n",
    "\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            tree_predictions = np.array([predict_tree(tree, x) for x in X])\n",
    "            predictions[:, i, :] = self.learning_rate * tree_predictions\n",
    "\n",
    "        return softmax(np.sum(predictions, axis=1))\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        probabilities = self.predict_proba(X)\n",
    "        return np.argmax(probabilities, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8032f9",
   "metadata": {},
   "source": [
    "## Evaluating Our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257dbee3",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce449a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n",
      "Training Time: 3019.93 milliseconds\n"
     ]
    }
   ],
   "source": [
    "iris = pd.read_csv(\"iris.csv\")\n",
    "iris = iris.drop('Id', axis=1)\n",
    "\n",
    "X = iris.iloc[:, 0:4]\n",
    "y = iris['Species']\n",
    "labels = {item: index for index, item in enumerate(np.unique(y))}\n",
    "y = y.map(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, test_size=0.2, shuffle=True)\n",
    "\n",
    "model = MyXGBoostClassifier(n_estimators=100, learning_rate=0.5, max_depth=3)\n",
    "start_time = time.perf_counter()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "predictions = model.predict(X_test)\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea958c3b",
   "metadata": {},
   "source": [
    "### Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8a3797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n",
      "Training Time: 49606.25 milliseconds\n"
     ]
    }
   ],
   "source": [
    "breast_cancer = pd.read_csv(\"data.csv\")\n",
    "breast_cancer = breast_cancer.drop('id', axis=1)\n",
    "\n",
    "X = breast_cancer.iloc[:, 2:]\n",
    "y = breast_cancer['diagnosis']\n",
    "labels = {item: index for index, item in enumerate(np.unique(y))}\n",
    "y = y.map(labels)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, test_size=0.2, shuffle=True)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "\n",
    "\n",
    "\n",
    "model = MyXGBoostClassifier(n_estimators=5, learning_rate=0.5, max_depth=10)\n",
    "start_time = time.perf_counter()\n",
    "model.fit(X_train_imputed, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "predictions = model.predict(X_test_imputed)\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f5e125",
   "metadata": {},
   "source": [
    "### Ann Thyroid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3091c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3420: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9215277777777777\n",
      "Training Time: 18964.69 milliseconds\n"
     ]
    }
   ],
   "source": [
    "X3, y3 = fetch_data('ann_thyroid', return_X_y=True, local_cache_dir='./')\n",
    "\n",
    "conditions = [y3 == 1, y3 == 2, y3 == 3]\n",
    "values = [0, 1, 2]\n",
    "\n",
    "y3 = np.select(conditions, values, default=y3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, random_state=10, test_size=0.2, shuffle=True)\n",
    "\n",
    "model = MyXGBoostClassifier(n_estimators=10, learning_rate=0.1, max_depth=3)\n",
    "start_time = time.perf_counter()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81382997",
   "metadata": {},
   "source": [
    "## Using XGBoost from library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5f6e6",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813c62aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Training Time: 19.49 milliseconds\n"
     ]
    }
   ],
   "source": [
    "iris = pd.read_csv(\"iris.csv\")\n",
    "iris = iris.drop('Id', axis=1)\n",
    "\n",
    "X = iris.iloc[:, 0:4]\n",
    "y = iris['Species']\n",
    "labels = {item: index for index, item in enumerate(np.unique(y))}\n",
    "y = y.map(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, test_size=0.2, shuffle=True)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softmax\", \n",
    "    \"num_class\": len(np.unique(y)),\n",
    "    \"max_depth\": 3,                \n",
    "    \"learning_rate\": 0.5,                     \n",
    "}\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "model = xgb.train(params, dtrain)\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fa1e0f",
   "metadata": {},
   "source": [
    "### Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bafb1a1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7758620689655172\n",
      "Training Time (ms): 9.48540001991205\n"
     ]
    }
   ],
   "source": [
    "X2, y2 = fetch_data('breast_cancer', return_X_y=True, local_cache_dir='./')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, random_state=10, test_size=0.2, shuffle=True)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softmax\",  \n",
    "    \"num_class\": len(np.unique(y2)),\n",
    "    \"max_depth\": 3,                 \n",
    "    \"learning_rate\": 0.1,                    \n",
    "}\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "model = xgb.train(params, dtrain)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Training Time (ms):\", elapsed_time_microsec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c93bbf3",
   "metadata": {},
   "source": [
    "### Ann Thyroid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592a5928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9909722222222223\n",
      "Training Time: 24.34 milliseconds\n"
     ]
    }
   ],
   "source": [
    "X4, y4 = fetch_data('ann_thyroid', return_X_y=True, local_cache_dir='./')\n",
    "\n",
    "conditions = [y4 == 1, y4 == 2, y4 == 3]\n",
    "values = [0, 1, 2]\n",
    "\n",
    "y4 = np.select(conditions, values, default=y4)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, y4, random_state=10, test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softmax\",  \n",
    "    \"num_class\": len(np.unique(y4)),       \n",
    "    \"max_depth\": 3,                  \n",
    "    \"learning_rate\": 0.1,                         \n",
    "}\n",
    "\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "model = xgb.train(params, dtrain)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "elapsed_time_millisec = (end_time - start_time) * 1000\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred_int = y_pred.astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_int))\n",
    "print(f\"Training Time: {elapsed_time_millisec:.2f} milliseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2487b91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
