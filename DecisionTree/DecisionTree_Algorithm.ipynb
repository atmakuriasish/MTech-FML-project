{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b06ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier as skverdtc\n",
    "from pmlb import fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "058725ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        n_samples, n_features = X.shape\n",
    "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "\n",
    "        if (len(unique_classes) == 1) or (depth == self.max_depth) or (n_samples < self.min_samples_split):\n",
    "            # If all samples have the same class or the tree depth limit is reached,\n",
    "            # create a leaf node with the most common class\n",
    "            return unique_classes[np.argmax(class_counts)]\n",
    "\n",
    "        # Find the best split based on information gain\n",
    "        best_split = self._find_best_split(X, y)\n",
    "\n",
    "        if best_split is None:\n",
    "            # If no split improves information gain, create a leaf node\n",
    "            return unique_classes[np.argmax(class_counts)]\n",
    "\n",
    "        # Create a decision node based on the best split\n",
    "        feature_index, threshold, gini = best_split\n",
    "        node = {}\n",
    "        node[\"feature_index\"] = feature_index\n",
    "        node[\"threshold\"] = threshold\n",
    "        node[\"left\"] = self._build_tree(X[X[:, feature_index] <= threshold], y[X[:, feature_index] <= threshold], depth + 1)\n",
    "        node[\"right\"] = self._build_tree(X[X[:, feature_index] > threshold], y[X[:, feature_index] > threshold], depth + 1)\n",
    "        node[\"gini\"] = gini\n",
    "        node[\"num_samples\"] = class_counts\n",
    "        node[\"depth\"] = depth\n",
    "        return node\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        gini = self._calculate_gini(y) \n",
    "\n",
    "        best_info_gain = 0\n",
    "        best_split = None\n",
    "\n",
    "        for feature_index in range(n_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                y_left = y[X[:, feature_index] <= threshold]\n",
    "                y_right = y[X[:, feature_index] > threshold]\n",
    "\n",
    "                if len(y_left) == 0 or len(y_right) == 0:\n",
    "                    continue\n",
    "\n",
    "                p_left = len(y_left) / n_samples\n",
    "                p_right = len(y_right) / n_samples\n",
    "                gain = gini - (p_left * self._calculate_gini(y_left) + p_right * self._calculate_gini(y_right))\n",
    "\n",
    "                if gain > best_info_gain:\n",
    "                    best_info_gain = gain\n",
    "                    best_split = (feature_index, threshold, gini)\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    def _calculate_gini(self, y):\n",
    "        _, class_counts = np.unique(y, return_counts=True)\n",
    "        return 1.0 - sum((count / len(y)) ** 2 for count in class_counts)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_tree(x, self.tree) for x in X])\n",
    "\n",
    "    def _predict_tree(self, x, tree):\n",
    "        if isinstance(tree, np.int64) or isinstance(tree, np.int32):\n",
    "            return tree\n",
    "        feature_index, threshold, left_tree, right_tree = tree[\"feature_index\"], tree[\"threshold\"], tree[\"left\"], tree[\"right\"]\n",
    "        if x[feature_index] <= threshold:\n",
    "            return self._predict_tree(x, left_tree)\n",
    "        else:\n",
    "            return self._predict_tree(x, right_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becf6a0e",
   "metadata": {},
   "source": [
    "## Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9825ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n",
      "Training Time: 39.29 milliseconds\n",
      "Accuracy: 1.0\n",
      "Training Time: 2.76 milliseconds\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "start_time = time.perf_counter()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")\n",
    "\n",
    "clf2 = skverdtc()\n",
    "start_time = time.perf_counter()\n",
    "clf2.fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "y_pred = clf2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043e077",
   "metadata": {},
   "source": [
    "## Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92218d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7758620689655172\n",
      "Training Time: 49.05 milliseconds\n",
      "Accuracy: 0.6379310344827587\n",
      "Training Time: 4.65 milliseconds\n"
     ]
    }
   ],
   "source": [
    "X2, y2 = fetch_data('breast_cancer', return_X_y=True, local_cache_dir='./')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X2, y2, random_state=10, test_size=0.2, shuffle=True)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=3)\n",
    "start_time = time.perf_counter()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")\n",
    "\n",
    "clf = skverdtc()\n",
    "start_time = time.perf_counter()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f3b6b2",
   "metadata": {},
   "source": [
    "## Ann Thyroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f9100a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99375\n",
      "Training Time: 806.40 milliseconds\n",
      "Accuracy: 0.9972222222222222\n",
      "Training Time: 10.54 milliseconds\n"
     ]
    }
   ],
   "source": [
    "X3, y3 = fetch_data('ann_thyroid', return_X_y=True, local_cache_dir='./')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X3, y3, random_state=10, test_size=0.2, shuffle=True)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=4)\n",
    "start_time = time.perf_counter()\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")\n",
    "\n",
    "clf = skverdtc()\n",
    "start_time = time.perf_counter()\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "elapsed_time_microsec = (end_time - start_time) * 1000\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))\n",
    "print(f\"Training Time: {elapsed_time_microsec:.2f} milliseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f838c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d02ec4b8",
   "metadata": {},
   "source": [
    "## XGBoost (Ann Thyroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e86a70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9909722222222223\n",
      "Training Time: 25.43 milliseconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\ML\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [12:12:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "X4, y4 = fetch_data('ann_thyroid', return_X_y=True, local_cache_dir='./')\n",
    "\n",
    "conditions = [y4 == 1, y4 == 2, y4 == 3]\n",
    "values = [0, 1, 2]\n",
    "\n",
    "y4 = np.select(conditions, values, default=y4)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, y4, random_state=10, test_size=0.2, shuffle=True)\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"multi:softmax\",  \n",
    "    \"num_class\": len(np.unique(y4)),       \n",
    "    \"max_depth\": 3,                  \n",
    "    \"learning_rate\": 0.1,            \n",
    "    \"n_estimators\": 500              \n",
    "}\n",
    "\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "model = xgb.train(params, dtrain)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "elapsed_time_millisec = (end_time - start_time) * 1000\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "y_pred_int = y_pred.astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_int))\n",
    "print(f\"Training Time: {elapsed_time_millisec:.2f} milliseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b051144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
